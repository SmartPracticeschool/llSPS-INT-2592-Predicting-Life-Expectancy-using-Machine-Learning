{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict House Value using Watson Studio\n",
    "\n",
    "In this notebook we will walk through a simple machine learning example in order to explore ways to leverage Watson Studio to simplify building and collaborating on AI and data science applications.\n",
    "\n",
    "## Learning Goals\n",
    "1. Understand what Watson Studio is and the value it brings\n",
    "1. Build simple 3 simple models\n",
    "1. Understand the deployment pipeline with Watson Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data\n",
    "In the cell above, import the CSV into our notebook from Watson Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT DATA FRAME HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMORTANT \n",
    "Set the value of `my_df` to the variable assigned by Watson for the dataframe (in this case, Watson used `df_data_1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = df_data_2 # CHANGE df_data_X TO YOUR VARIABLE FROM ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Observations\n",
    "\n",
    "Lets first take a visual look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.hist(bins=50, figsize=(30, 25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data\n",
    "\n",
    "Before we do anything further, we want to make sure the data is usable. In this case, all we have to do is take care of any missing values in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 15 # Anything that occurs less than N times will be removed.\n",
    "\n",
    "# We only want to remove values from non-numeric columns\n",
    "for col in my_df.select_dtypes(include=['object']).columns:\n",
    "    my_df[col].fillna('NA', inplace = True)\n",
    "    value_counts = my_df[col].value_counts() # Specific column \n",
    "    to_remove = value_counts[value_counts <= threshold].index\n",
    "    my_df[col].replace(to_remove, 'NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data\n",
    "\n",
    "Now that the data is cleaned, we are ready to begin building some models! In this example, we will be building a model to predict `SALEPRICE` based on the other feratures in the data. First, we'll split our data into two sets, training and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variable we want to predict\n",
    "y = my_df['SALEPRICE']\n",
    "\n",
    "my_df = my_df.drop(['SALEPRICE','ID'],  axis=1)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "X_2 = my_df.apply(le.fit_transform)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "ft = enc.fit(X_2)\n",
    "\n",
    "onehotlabels = enc.transform(X_2).toarray()\n",
    "onehotlabels.shape\n",
    "\n",
    "x = X_2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression(fit_intercept=False)\n",
    "linear_regression_model = regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_mse = mean_squared_error(y_pred, y_test)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "\n",
    "print('Linear Regression RMSE: $%.4f' % lin_rmse)\n",
    "\n",
    "lin_mae = mean_absolute_error(y_pred, y_test)\n",
    "print('Linear Regression MAE: $%.4f' % lin_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "forest_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest R squared\": %.4f' % forest_reg.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest_reg.predict(x_test)\n",
    "forest_mse = mean_squared_error(y_pred, y_test)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "\n",
    "print('Random Forest RMSE: $%.4f' % forest_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gradient Boosting R squared\": %.4f' % model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "model_mse = mean_squared_error(y_pred, y_test)\n",
    "model_rmse = np.sqrt(model_mse)\n",
    "\n",
    "print('Gradient Boosting RMSE: $%.4f' % model_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a Model with Watson Machine Learning\n",
    "\n",
    "One of the benefits of using a service like Watson Machine Learning is it allows data scientists and researchers to focus on building the best possible models, while not having to worry about infrastrucre to make those models usable by others. Here we will build a simple deployment pipeline to deploy one of our models from above and make it accessible through a private API.\n",
    "\n",
    "In this example we will choose to deploy the **Random Forest** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(my_df, y)\n",
    "\n",
    "categorical_feature_mask = (my_df.dtypes==object)\n",
    "numerical_features = ~categorical_feature_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_feature_mask),\n",
    "    (make_pipeline(SimpleImputer(), StandardScaler()), numerical_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(preprocess, RandomForestRegressor(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watson Machine Learning\n",
    "In the cell below, fill in the credentials for your Watson Machine Learning instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the credentials that you got from Watson Machine Learning service\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "wml_credentials = {\n",
    "    \"apikey\": \"<API KEY>\",\n",
    "    \"instance_id\": \"<INSTANCE ID>\",\n",
    "    \"url\": \"<URL>\"\n",
    "}\n",
    "\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes_meta = {\n",
    "    client.runtimes.ConfigurationMetaNames.NAME: \"House_Value_Model\", \n",
    "    client.runtimes.ConfigurationMetaNames.DESCRIPTION: \"House Value Model\", \n",
    "    client.runtimes.ConfigurationMetaNames.PLATFORM: { \"name\": \"python\", \"version\": \"3.6\" }, \n",
    "}\n",
    "runtime_details = client.runtimes.store(runtimes_meta)\n",
    "runtime_details\n",
    "runtime_url = client.runtimes.get_url(runtime_details)\n",
    "runtime_uid = client.runtimes.get_uid(runtime_details)\n",
    "print(\"Runtimes URL: \" + runtime_url)\n",
    "print(\"Runtimes UID: \" + runtime_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {client.repository.ModelMetaNames.NAME: \"House Value Model\",\n",
    "               client.repository.ModelMetaNames.RUNTIME_UID: runtime_uid\n",
    "              }\n",
    "published_model = client.repository.store_model(model=model, meta_props=model_props)\n",
    "import json\n",
    "published_model_uid = client.repository.get_model_uid(published_model)\n",
    "model_details = client.repository.get_details(published_model_uid)\n",
    "print(json.dumps(model_details, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_deployment = client.deployments.create(published_model_uid, name=\"House_Value_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint = client.deployments.get_scoring_url(created_deployment)\n",
    "print(scoring_endpoint)\n",
    "x_train.iloc[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the deployed model\n",
    "Now that we've deployed the model, we can now send a request to the API endpoint with a data payload to get a house price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_payload = {'fields': ['LOTAREA', 'BLDGTYPE', 'HOUSESTYLE', 'OVERALLCOND', 'YEARBUILT',\n",
    "       'ROOFSTYLE', 'EXTERCOND', 'FOUNDATION', 'BSMTCOND', 'HEATING',\n",
    "       'HEATINGQC', 'CENTRALAIR', 'ELECTRICAL', 'FULLBATH', 'HALFBATH',\n",
    "       'BEDROOMABVGR', 'KITCHENABVGR', 'KITCHENQUAL', 'TOTRMSABVGRD',\n",
    "       'FIREPLACES', 'FIREPLACEQU', 'GARAGETYPE', 'GARAGEFINISH', 'GARAGECARS',\n",
    "       'GARAGECOND', 'POOLAREA', 'POOLQC', 'FENCE', 'MOSOLD', 'YRSOLD' ], \n",
    "                   'values': [[9000, '1Fam', '2Story', 9, 1920, 'Hip', 'Gd', 'PConc', 'TA',\n",
    "       'GasA', 'Ex', 'Y', 'SBrkr', 1, 0, 3, 1, 'TA', 7, 0, 'NA', 'Detchd',\n",
    "       'Unf', 2, 'TA', 0, 'NA', 'NA', 7, 2009]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = client.deployments.score(scoring_endpoint, scoring_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
